{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow Project and Model Example\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://raw.githubusercontent.com/dmatrix/mlflow-workshop-part-2/master/images/models_1.png\"\n",
    "         alt=\"Bank Note \" width=\"400\">\n",
    "  </td></tr>\n",
    "  <tr><td> Save a Keras Model Flavor and load as both Keras Native Flavor and PyFunc Flavor</td></tr>\n",
    "  <tr><td>\n",
    "    <img src=\"https://raw.githubusercontent.com/dmatrix/mlflow-workshop-part-2/master/images/models_2.png\"\n",
    "         alt=\"Bank Note \" width=\"400\">\n",
    "  </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/julesdamji/.conda/envs/tutorials/lib/python3.7/site-packages (2.3.1)\r\n",
      "Requirement already satisfied: h5py in /Users/julesdamji/.conda/envs/tutorials/lib/python3.7/site-packages (from keras) (2.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /Users/julesdamji/.conda/envs/tutorials/lib/python3.7/site-packages (from keras) (5.3.1)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/julesdamji/.conda/envs/tutorials/lib/python3.7/site-packages (from keras) (1.3.1)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/julesdamji/.conda/envs/tutorials/lib/python3.7/site-packages (from keras) (1.0.8)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/julesdamji/.conda/envs/tutorials/lib/python3.7/site-packages (from keras) (1.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/julesdamji/.conda/envs/tutorials/lib/python3.7/site-packages (from keras) (1.17.4)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/julesdamji/.conda/envs/tutorials/lib/python3.7/site-packages (from keras) (1.13.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow.keras\n",
    "import mlflow.pyfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow version=1.10.0;keras version=2.3.1;tensorlow version=2.0.0\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "print(f\"mlflow version={mlflow.__version__};keras version={keras.__version__};tensorlow version={tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://androidkt.com/linear-regression-model-in-keras/)\n",
    "Modified and extended for this tutorial\n",
    "\n",
    "Problem: Build a simple Linear NN Model that predicts Celsius temperaturers from training data with Fahrenheit degree\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://raw.githubusercontent.com/dmatrix/mlflow-workshop-part-2/master/images/temperature-conversion.png\"\n",
    "         alt=\"Bank Note \" width=\"600\">\n",
    "  </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate our X, y, and predict data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2c(f):\n",
    "  return (f - 32) * 5.0/9.0\n",
    "\n",
    "def gen_data(start, stop, step):\n",
    "    X_fahrenheit = np.arange(start, stop, step, dtype=float)\n",
    "    # Randomize the input\n",
    "    np.random.shuffle(X_fahrenheit)\n",
    "    y_celsius = np.array(np.array([f2c(f) for f in X_fahrenheit]))\n",
    "\n",
    "    predict_data =[]\n",
    "    [predict_data.append(t) for t in range (212, 170, -5)]\n",
    "    \n",
    "    return (X_fahrenheit, y_celsius, predict_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keras_model(uri, data):\n",
    "  model = mlflow.keras.load_model(uri)\n",
    "  return [(f\"(F={f}, C={model.predict([f])[0]})\") for f in data]\n",
    "\n",
    "def predict_pyfunc_model(uri, data):\n",
    "  # Given Fahrenheit -> Predict Celcius\n",
    "  # Create a pandas DataFrame with Fahrenheit unseen values\n",
    "  # Get the Celius prediction\n",
    "  pyfunc_model = mlflow.pyfunc.load_model(uri)\n",
    "  df = pd.DataFrame(np.array(data))\n",
    "  return pyfunc_model.predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a Keras Dense NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def baseline_model():\n",
    "   model = keras.Sequential([\n",
    "      keras.layers.Dense(64, activation='relu', input_shape=[1]),\n",
    "      keras.layers.Dense(64, activation='relu'),\n",
    "      keras.layers.Dense(1)\n",
    "   ])\n",
    "\n",
    "   optimizer = keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "   # Compile the model\n",
    "   model.compile(loss='mean_squared_error',\n",
    "                 optimizer=optimizer,\n",
    "                 metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "   return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capture run metrics using MLflow API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `model.<flavor>.autolog()`, you don't need to log parameter, metrics, models etc.\n",
    "autlogging is a convenient method to make it easier to use MLflow Fluent APIs, hence making your code eaiser to read.\n",
    "  * Autologgin Features for [Model Flavors](https://mlflow.org/docs/latest/tracking.html#automatic-logging)\n",
    "  * PR for in development:\n",
    "    * `mlflow.pytorch.autolog()`\n",
    "    * `mlflow.scklearn.autolog()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run(params, X, y, run_name=\"Keras Linear Regression\"):\n",
    "\n",
    "   # Start MLflow run and log everyting...\n",
    "   with mlflow.start_run(run_name=run_name) as run:\n",
    "      \n",
    "      run_id = run.info.run_uuid\n",
    "      exp_id = run.info.experiment_id\n",
    "      \n",
    "      model = baseline_model()\n",
    "      # single line of MLflow Fluent API obviates the need to log\n",
    "      # individual parameters, metrics, model, artifacts etc...\n",
    "      # https://mlflow.org/docs/latest/python_api/mlflow.keras.html#mlflow.keras.autolog\n",
    "      mlflow.keras.autolog()\n",
    "      model.fit(X, y, batch_size=params['batch_size'], epochs=params['epochs'])\n",
    "\n",
    "      return (exp_id, run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate X, y, and predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y, predict_data) = gen_data(-212, 10512, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5362/5362 [==============================] - 1s 210us/step - loss: 159532.5550 - mean_absolute_error: 99.0227 - mean_squared_error: 159532.5469\n",
      "Epoch 2/100\n",
      "5362/5362 [==============================] - 1s 135us/step - loss: 3617.5308 - mean_absolute_error: 36.6232 - mean_squared_error: 3617.5278\n",
      "Epoch 3/100\n",
      "5362/5362 [==============================] - 1s 115us/step - loss: 3966.4504 - mean_absolute_error: 38.1679 - mean_squared_error: 3966.4507\n",
      "Epoch 4/100\n",
      "5362/5362 [==============================] - 1s 116us/step - loss: 3566.5927 - mean_absolute_error: 38.3598 - mean_squared_error: 3566.5916\n",
      "Epoch 5/100\n",
      "5362/5362 [==============================] - 1s 116us/step - loss: 2808.7524 - mean_absolute_error: 31.6331 - mean_squared_error: 2808.7517\n",
      "Epoch 6/100\n",
      "5362/5362 [==============================] - 1s 130us/step - loss: 2552.8920 - mean_absolute_error: 32.4932 - mean_squared_error: 2552.8914\n",
      "Epoch 7/100\n",
      "5362/5362 [==============================] - 1s 117us/step - loss: 2242.3982 - mean_absolute_error: 27.9757 - mean_squared_error: 2242.3992\n",
      "Epoch 8/100\n",
      "5362/5362 [==============================] - 1s 114us/step - loss: 2116.1172 - mean_absolute_error: 28.3972 - mean_squared_error: 2116.1167\n",
      "Epoch 9/100\n",
      "5362/5362 [==============================] - 1s 120us/step - loss: 2141.1045 - mean_absolute_error: 27.3145 - mean_squared_error: 2141.1052\n",
      "Epoch 10/100\n",
      "5362/5362 [==============================] - 1s 120us/step - loss: 1894.6329 - mean_absolute_error: 27.7276 - mean_squared_error: 1894.6329\n",
      "Epoch 11/100\n",
      "5362/5362 [==============================] - 1s 116us/step - loss: 1819.0373 - mean_absolute_error: 26.0410 - mean_squared_error: 1819.0370\n",
      "Epoch 12/100\n",
      "5362/5362 [==============================] - 1s 115us/step - loss: 1859.1442 - mean_absolute_error: 27.8122 - mean_squared_error: 1859.1442\n",
      "Epoch 13/100\n",
      "5362/5362 [==============================] - 1s 116us/step - loss: 1766.3854 - mean_absolute_error: 25.1139 - mean_squared_error: 1766.3856\n",
      "Epoch 14/100\n",
      "5362/5362 [==============================] - 1s 115us/step - loss: 1693.2217 - mean_absolute_error: 26.4057 - mean_squared_error: 1693.2216\n",
      "Epoch 15/100\n",
      "5362/5362 [==============================] - 1s 114us/step - loss: 1544.5167 - mean_absolute_error: 25.2765 - mean_squared_error: 1544.5168\n",
      "Epoch 16/100\n",
      "5362/5362 [==============================] - 1s 119us/step - loss: 1399.9807 - mean_absolute_error: 23.8614 - mean_squared_error: 1399.9810\n",
      "Epoch 17/100\n",
      "5362/5362 [==============================] - 1s 114us/step - loss: 1402.3258 - mean_absolute_error: 23.9835 - mean_squared_error: 1402.3253\n",
      "Epoch 18/100\n",
      "5362/5362 [==============================] - 1s 113us/step - loss: 1372.6955 - mean_absolute_error: 24.1994 - mean_squared_error: 1372.6952\n",
      "Epoch 19/100\n",
      "5362/5362 [==============================] - 1s 114us/step - loss: 1378.8410 - mean_absolute_error: 22.3323 - mean_squared_error: 1378.8408\n",
      "Epoch 20/100\n",
      "5362/5362 [==============================] - 1s 120us/step - loss: 1379.2892 - mean_absolute_error: 23.8145 - mean_squared_error: 1379.2892\n",
      "Epoch 21/100\n",
      "5362/5362 [==============================] - 1s 113us/step - loss: 1331.9456 - mean_absolute_error: 24.2217 - mean_squared_error: 1331.9457\n",
      "Epoch 22/100\n",
      "5362/5362 [==============================] - 1s 115us/step - loss: 1281.2323 - mean_absolute_error: 23.6607 - mean_squared_error: 1281.2323\n",
      "Epoch 23/100\n",
      "5362/5362 [==============================] - 1s 120us/step - loss: 1217.7361 - mean_absolute_error: 23.4045 - mean_squared_error: 1217.7360\n",
      "Epoch 24/100\n",
      "5362/5362 [==============================] - 1s 121us/step - loss: 1269.6213 - mean_absolute_error: 22.0027 - mean_squared_error: 1269.6213\n",
      "Epoch 25/100\n",
      "5362/5362 [==============================] - 1s 118us/step - loss: 1216.3886 - mean_absolute_error: 22.0520 - mean_squared_error: 1216.3885\n",
      "Epoch 26/100\n",
      "5362/5362 [==============================] - 1s 117us/step - loss: 1209.3041 - mean_absolute_error: 22.7708 - mean_squared_error: 1209.3040\n",
      "Epoch 27/100\n",
      "5362/5362 [==============================] - 1s 116us/step - loss: 1203.0075 - mean_absolute_error: 22.0653 - mean_squared_error: 1203.0078\n",
      "Epoch 28/100\n",
      "5362/5362 [==============================] - 1s 114us/step - loss: 1126.8493 - mean_absolute_error: 20.5283 - mean_squared_error: 1126.8497\n",
      "Epoch 29/100\n",
      "5362/5362 [==============================] - 1s 116us/step - loss: 1099.2319 - mean_absolute_error: 20.5286 - mean_squared_error: 1099.2323\n",
      "Epoch 30/100\n",
      "5362/5362 [==============================] - 1s 118us/step - loss: 1066.8116 - mean_absolute_error: 20.4777 - mean_squared_error: 1066.8120\n",
      "Epoch 31/100\n",
      "5362/5362 [==============================] - 1s 113us/step - loss: 1047.2227 - mean_absolute_error: 19.8639 - mean_squared_error: 1047.2224\n",
      "Epoch 32/100\n",
      "5362/5362 [==============================] - 1s 122us/step - loss: 1025.7856 - mean_absolute_error: 19.0678 - mean_squared_error: 1025.7856\n",
      "Epoch 33/100\n",
      "5362/5362 [==============================] - 1s 115us/step - loss: 1004.7006 - mean_absolute_error: 18.7936 - mean_squared_error: 1004.7007\n",
      "Epoch 34/100\n",
      "5362/5362 [==============================] - 1s 113us/step - loss: 990.8980 - mean_absolute_error: 18.8545 - mean_squared_error: 990.8972\n",
      "Epoch 35/100\n",
      "5362/5362 [==============================] - 1s 122us/step - loss: 930.4493 - mean_absolute_error: 19.1687 - mean_squared_error: 930.4491\n",
      "Epoch 36/100\n",
      "5362/5362 [==============================] - 1s 117us/step - loss: 961.8612 - mean_absolute_error: 18.4041 - mean_squared_error: 961.8607\n",
      "Epoch 37/100\n",
      "5362/5362 [==============================] - 1s 113us/step - loss: 931.0429 - mean_absolute_error: 18.7381 - mean_squared_error: 931.0426\n",
      "Epoch 38/100\n",
      "5362/5362 [==============================] - 1s 113us/step - loss: 901.9257 - mean_absolute_error: 19.1152 - mean_squared_error: 901.9260\n",
      "Epoch 39/100\n",
      "5362/5362 [==============================] - 1s 118us/step - loss: 908.5420 - mean_absolute_error: 18.7103 - mean_squared_error: 908.5419\n",
      "Epoch 40/100\n",
      "5362/5362 [==============================] - 1s 122us/step - loss: 870.4108 - mean_absolute_error: 18.5696 - mean_squared_error: 870.4108\n",
      "Epoch 41/100\n",
      "5362/5362 [==============================] - 1s 137us/step - loss: 897.3993 - mean_absolute_error: 18.9589 - mean_squared_error: 897.3988\n",
      "Epoch 42/100\n",
      "5362/5362 [==============================] - 1s 121us/step - loss: 887.3622 - mean_absolute_error: 17.6895 - mean_squared_error: 887.3619\n",
      "Epoch 43/100\n",
      "5362/5362 [==============================] - 1s 128us/step - loss: 871.3333 - mean_absolute_error: 16.9742 - mean_squared_error: 871.3336\n",
      "Epoch 44/100\n",
      "5362/5362 [==============================] - 1s 122us/step - loss: 858.0174 - mean_absolute_error: 17.3693 - mean_squared_error: 858.0177\n",
      "Epoch 45/100\n",
      "5362/5362 [==============================] - 1s 119us/step - loss: 809.3781 - mean_absolute_error: 16.5805 - mean_squared_error: 809.3783\n",
      "Epoch 46/100\n",
      "5362/5362 [==============================] - 1s 117us/step - loss: 825.5778 - mean_absolute_error: 17.1001 - mean_squared_error: 825.5781\n",
      "Epoch 47/100\n",
      "5362/5362 [==============================] - 1s 118us/step - loss: 836.5533 - mean_absolute_error: 17.5961 - mean_squared_error: 836.5530\n",
      "Epoch 48/100\n",
      "5362/5362 [==============================] - 1s 115us/step - loss: 816.0825 - mean_absolute_error: 17.7151 - mean_squared_error: 816.0826\n",
      "Epoch 49/100\n",
      "5362/5362 [==============================] - 1s 121us/step - loss: 817.3407 - mean_absolute_error: 16.0114 - mean_squared_error: 817.3411\n",
      "Epoch 50/100\n",
      "5362/5362 [==============================] - 1s 121us/step - loss: 833.5527 - mean_absolute_error: 16.9424 - mean_squared_error: 833.5522\n",
      "Epoch 51/100\n",
      "5362/5362 [==============================] - 1s 115us/step - loss: 794.6812 - mean_absolute_error: 17.2055 - mean_squared_error: 794.6812\n",
      "Epoch 52/100\n",
      "5362/5362 [==============================] - 1s 115us/step - loss: 779.4199 - mean_absolute_error: 15.9578 - mean_squared_error: 779.4201\n",
      "Epoch 53/100\n",
      "5362/5362 [==============================] - 1s 122us/step - loss: 780.4485 - mean_absolute_error: 15.7734 - mean_squared_error: 780.4489\n",
      "Epoch 54/100\n",
      "5362/5362 [==============================] - 1s 114us/step - loss: 805.7802 - mean_absolute_error: 16.0775 - mean_squared_error: 805.7797\n",
      "Epoch 55/100\n",
      "5362/5362 [==============================] - 1s 117us/step - loss: 770.5242 - mean_absolute_error: 16.3383 - mean_squared_error: 770.5246\n",
      "Epoch 56/100\n",
      "5362/5362 [==============================] - 1s 116us/step - loss: 769.3333 - mean_absolute_error: 16.0514 - mean_squared_error: 769.3330\n",
      "Epoch 57/100\n",
      "5362/5362 [==============================] - 1s 115us/step - loss: 763.6809 - mean_absolute_error: 15.9510 - mean_squared_error: 763.6812\n",
      "Epoch 58/100\n",
      "5362/5362 [==============================] - 1s 125us/step - loss: 760.7647 - mean_absolute_error: 15.2836 - mean_squared_error: 760.7646\n",
      "Epoch 59/100\n",
      "5362/5362 [==============================] - 1s 120us/step - loss: 743.4154 - mean_absolute_error: 16.3474 - mean_squared_error: 743.4155\n",
      "Epoch 60/100\n",
      "5362/5362 [==============================] - 1s 118us/step - loss: 766.4696 - mean_absolute_error: 15.8673 - mean_squared_error: 766.4697\n",
      "Epoch 61/100\n",
      "5362/5362 [==============================] - 1s 116us/step - loss: 743.8897 - mean_absolute_error: 15.0789 - mean_squared_error: 743.8895\n",
      "Epoch 62/100\n",
      "5362/5362 [==============================] - 1s 122us/step - loss: 748.2073 - mean_absolute_error: 16.3732 - mean_squared_error: 748.2074\n",
      "Epoch 63/100\n",
      "5362/5362 [==============================] - 1s 124us/step - loss: 751.6312 - mean_absolute_error: 15.5877 - mean_squared_error: 751.6310\n",
      "Epoch 64/100\n",
      "5362/5362 [==============================] - 1s 117us/step - loss: 716.8006 - mean_absolute_error: 15.7234 - mean_squared_error: 716.8005\n",
      "Epoch 65/100\n",
      "5362/5362 [==============================] - 1s 116us/step - loss: 728.0692 - mean_absolute_error: 15.6711 - mean_squared_error: 728.0689\n",
      "Epoch 66/100\n",
      "5362/5362 [==============================] - 1s 130us/step - loss: 734.6973 - mean_absolute_error: 14.9717 - mean_squared_error: 734.6972\n",
      "Epoch 67/100\n",
      "5362/5362 [==============================] - 1s 147us/step - loss: 721.5753 - mean_absolute_error: 16.2546 - mean_squared_error: 721.5753\n",
      "Epoch 68/100\n",
      "5362/5362 [==============================] - 1s 118us/step - loss: 724.0441 - mean_absolute_error: 14.8399 - mean_squared_error: 724.0443\n",
      "Epoch 69/100\n",
      "5362/5362 [==============================] - 1s 116us/step - loss: 735.1952 - mean_absolute_error: 15.2318 - mean_squared_error: 735.1951\n",
      "Epoch 70/100\n",
      "5362/5362 [==============================] - 1s 132us/step - loss: 852.7031 - mean_absolute_error: 16.1067 - mean_squared_error: 852.7032\n",
      "Epoch 71/100\n",
      "5362/5362 [==============================] - 1s 121us/step - loss: 696.3450 - mean_absolute_error: 14.7177 - mean_squared_error: 696.3453\n",
      "Epoch 72/100\n",
      "5362/5362 [==============================] - 1s 131us/step - loss: 721.0333 - mean_absolute_error: 15.5580 - mean_squared_error: 721.0337\n",
      "Epoch 73/100\n",
      "5362/5362 [==============================] - 1s 113us/step - loss: 700.1972 - mean_absolute_error: 14.2816 - mean_squared_error: 700.1971\n",
      "Epoch 74/100\n",
      "5362/5362 [==============================] - 1s 112us/step - loss: 680.2915 - mean_absolute_error: 15.1047 - mean_squared_error: 680.2914\n",
      "Epoch 75/100\n",
      "5362/5362 [==============================] - 1s 118us/step - loss: 744.8626 - mean_absolute_error: 14.8050 - mean_squared_error: 744.8627\n",
      "Epoch 76/100\n",
      "5362/5362 [==============================] - 1s 190us/step - loss: 711.6245 - mean_absolute_error: 14.7157 - mean_squared_error: 711.6242\n",
      "Epoch 77/100\n",
      "5362/5362 [==============================] - 1s 175us/step - loss: 679.0132 - mean_absolute_error: 14.6865 - mean_squared_error: 679.0131\n",
      "Epoch 78/100\n",
      "5362/5362 [==============================] - 1s 168us/step - loss: 678.2884 - mean_absolute_error: 14.0616 - mean_squared_error: 678.2883\n",
      "Epoch 79/100\n",
      "5362/5362 [==============================] - 1s 158us/step - loss: 653.3072 - mean_absolute_error: 15.3438 - mean_squared_error: 653.3073\n",
      "Epoch 80/100\n",
      "3420/5362 [==================>...........] - ETA: 0s - loss: 681.0834 - mean_absolute_error: 15.4065 - mean_squared_error: 681.0832"
     ]
    }
   ],
   "source": [
    "params = {'batch_size': 10,'epochs': 100}\n",
    "(exp_id, run_id) = mlflow_run(params, X, y)\n",
    "print(f\"Finished Experiment id={exp_id} and run id = {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the MLflow UI\n",
    " * check the Model file\n",
    " * check the Conda.yaml file\n",
    " * check the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Keras Model Flavor: Native Flavor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load this Keras Model Flavor as a Keras native model flavor and make a prediction\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "print(f\"Loading the Keras Model={model_uri} as Keras Model\")\n",
    "predictions = predict_keras_model(model_uri, predict_data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Keras Model Flavor as a PyFunc Flavor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load this Keras Model Flavor as a pyfunc model flavor and make a prediction\n",
    "pyfunc_uri = f\"runs:/{run_id}/model\"\n",
    "print(f\"Loading the Keras Model={pyfunc_uri} as Pyfunc Model\")\n",
    "predictions = predict_pyfunc_model(pyfunc_uri, predict_data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise/Lab Assignment\n",
    "\n",
    "Using what we have learning in this session:\n",
    "  * Can you decrease the MSE?\n",
    "  * Increase the size of input data\n",
    "  * Change the batch size and number of epochs\n",
    "      * Run at least three experiments with different parameters: number of epochs, batches\n",
    "  * Compare the runs and metrics\n",
    "  \n",
    "Were you able lower the MSE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHALLENGE**: Excercise/Lab Assignment\n",
    " * Convert this program as a GitHub MLflow Project\n",
    " * Use the Lab 1 [MLflow Project](https://github.com/mlflow/mlflow-example) as a template\n",
    " * Other examples are in [here](https://github.com/mlflow/mlflow/tree/master/examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "name": "2_run_example_keras_lr",
  "notebookId": 3028997146775900
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
