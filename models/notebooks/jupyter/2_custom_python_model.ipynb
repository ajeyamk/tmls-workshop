{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in /Users/julesdamji/.conda/envs/tutorials/lib/python3.7/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /Users/julesdamji/.conda/envs/tutorials/lib/python3.7/site-packages (from vaderSentiment) (2.23.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/julesdamji/.conda/envs/tutorials/lib/python3.7/site-packages (from requests->vaderSentiment) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/julesdamji/.conda/envs/tutorials/lib/python3.7/site-packages (from requests->vaderSentiment) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/julesdamji/.conda/envs/tutorials/lib/python3.7/site-packages (from requests->vaderSentiment) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/julesdamji/.conda/envs/tutorials/lib/python3.7/site-packages (from requests->vaderSentiment) (2020.6.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VaderSentiment Python Package\n",
    "\n",
    "You can read the orignal paper by authors [here](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import mlflow.pyfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some input text\n",
    "\n",
    "INPUT_TEXTS = [{'text': \"This is a bad ass movie. You got to see it! :-)\"},\n",
    "               {'text': \"Ricky Gervais is smart, witty, and creative!!!!!! :D\"},\n",
    "               {'text': \"LOL, this guy fell off a chair while sleeping and snoring in a meeting\"},\n",
    "               {'text': \"Men shoots himself while trying to steal a dog, OMG\"},\n",
    "               {'text': \"Yay!! Another good phone interview. I nailed it!!\"},\n",
    "               {'text': \"This is INSANE! I can't believe it. How could you do such a horrible thing?\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a SocialMediaAnalyserModel\n",
    "\n",
    "This is a subclass of [PythonModel](https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#mlflow.pyfunc.PythonModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SocialMediaAnalyserModel(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "   def __init__(self):\n",
    "      \"\"\"\n",
    "      Constructor for our Cusomized PyFunc Model Class\n",
    "      \"\"\"\n",
    "      # Initialize an instance of vader analyser\n",
    "      self._analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "   def _score(self, text):\n",
    "    \"\"\"\n",
    "    Private function to analyse the scores. It invokes model's \n",
    "    param: text to analyse\n",
    "    return: sentiment analyses scores\n",
    "    \"\"\"\n",
    "    scores = self._analyser.polarity_scores(text)\n",
    "    return scores\n",
    "\n",
    "   def predict(self, context, model_input):\n",
    "    \"\"\"\n",
    "    Implement the predict function required for PythonModel\n",
    "    \"\"\"\n",
    "    model_output = model_input.apply(lambda col: self._score(col))\n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run():\n",
    "  \n",
    "  # Save the conda environment for this model. \n",
    "  conda_env = {\n",
    "    'channels': ['defaults', 'conda-forge'],\n",
    "    'dependencies': [\n",
    "        'python=3.7.6',\n",
    "        'pip'],\n",
    "    'pip': [\n",
    "      'mlflow',\n",
    "      'cloudpickle==1.3.0',\n",
    "      'vaderSentiment==3.3.2'\n",
    "    ],\n",
    "    'name': 'mlflow-env'\n",
    "  }\n",
    "  \n",
    "  # Model name and create an instance of PyFuncModel\n",
    "  model_path = \"vader\"\n",
    "  vader_model = SocialMediaAnalyserModel()\n",
    "  with mlflow.start_run(run_name=\"Vader Sentiment Analysis\") as run:\n",
    "    # Log MLflow entities\n",
    "    mlflow.pyfunc.log_model(model_path, python_model=vader_model, conda_env=conda_env)\n",
    "    mlflow.log_param(\"algorithm\", \"VADER\")\n",
    "    mlflow.log_param(\"total_sentiments\", len(INPUT_TEXTS))\n",
    "\n",
    "    # Load back the model as a pyfunc_model for scoring\n",
    "    model_uri = f\"runs:/{run.info.run_uuid}/{model_path}\"\n",
    "    loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "    \n",
    "    # Use predict function to score output from the model\n",
    "    for i in range(len(INPUT_TEXTS)):\n",
    "       text = INPUT_TEXTS[i]['text']\n",
    "       mlflow.log_param(f\"text_{i}\", text)\n",
    "      \n",
    "      # Use predict function to score output from the model\n",
    "       model_input = pd.DataFrame([text])\n",
    "       scores = loaded_model.predict(model_input)\n",
    "       print(f\"<{text}> ------- {str(scores[0])}>\")\n",
    "       for index, value in scores.items():\n",
    "          [mlflow.log_metric(f\"{key}_{i}\", value) for key, value in value.items()]\n",
    "          \n",
    "    return run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log parameters, metrics, and model with MLflow APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<This is a bad ass movie. You got to see it! :-)> ------- {'neg': 0.0, 'neu': 0.542, 'pos': 0.458, 'compound': 0.7644}>\n",
      "<Ricky Gervais is smart, witty, and creative!!!!!! :D> ------- {'neg': 0.0, 'neu': 0.316, 'pos': 0.684, 'compound': 0.8957}>\n",
      "<LOL, this guy fell off a chair while sleeping and snoring in a meeting> ------- {'neg': 0.0, 'neu': 0.786, 'pos': 0.214, 'compound': 0.5473}>\n",
      "<Men shoots himself while trying to steal a dog, OMG> ------- {'neg': 0.262, 'neu': 0.738, 'pos': 0.0, 'compound': -0.4939}>\n",
      "<Yay!! Another good phone interview. I nailed it!!> ------- {'neg': 0.0, 'neu': 0.446, 'pos': 0.554, 'compound': 0.816}>\n",
      "<This is INSANE! I can't believe it. How could you do such a horrible thing?> ------- {'neg': 0.357, 'neu': 0.643, 'pos': 0.0, 'compound': -0.8034}>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ef7d7ef8d30745c7a9f3a4ca8c5efaca'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " mlflow_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise Assignment\n",
    "\n",
    " * Create some text input\n",
    " * load the model as a PyFuncModel\n",
    " * Invoke its predict method with each text\n",
    " * Do the scores change if you remove emojis and chat speak\" or \"text speak?\n",
    " * Print the scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "name": "2_custom_python_model",
  "notebookId": 2256134280124936
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
